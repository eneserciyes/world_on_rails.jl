{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10498e0d-17da-4b08-9987-784c2549c502",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import yaml, glob, lmdb, json\n",
    "import os, sys\n",
    "import cv2\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9e6c5166-726f-4d8c-b70c-9314fb14bb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "b\n"
     ]
    }
   ],
   "source": [
    "test = {\"a\": 1, \"b\":2}\n",
    "for i in test:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42172df3-4c4d-4817-9acc-e2770edc8bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetToLMDB:\n",
    "    def __init__(self, data_dir, config_path):\n",
    "        self.data_dir = data_dir\n",
    "        \n",
    "        with open(config_path, 'r') as f:\n",
    "            config = yaml.safe_load(f)\n",
    "        self.camera_yaws = config['camera_yaws']\n",
    "        \n",
    "        # Ablation options\n",
    "        self.multi_cam = config['multi_cam']\n",
    "        self.total_image_size = 0\n",
    "    \n",
    "    def read_and_put_image(self, txn, image_path):\n",
    "        image_name, extension = os.path.splitext(os.path.basename(image_path))\n",
    "        with open(image_path, \"rb\") as img:\n",
    "            img_np = np.fromfile(img, np.dtype('B'))\n",
    "            txn.put(image_name.encode(), img_np)\n",
    "        return sys.getsizeof(img_np)\n",
    "\n",
    "    def read_and_put_label(self, txn, i, current_dir):\n",
    "        lbl_paths = [os.path.join(current_dir, \"rgbs\", f\"lbl_{d:02d}_{i:05d}.png\") for d in range(0,12)]\n",
    "        for path in lbl_paths:\n",
    "            self.read_and_put_image(txn, path)\n",
    "                     \n",
    "    def put_data(self, txn, data, current_dir):\n",
    "        \"\"\"\n",
    "        @param:\n",
    "        txn - open transaction on lmdb\n",
    "        data - dictionary containing location, rotation, speed and labels\n",
    "        \"\"\"\n",
    "        n = data['len']\n",
    "        txn.put('len'.encode(), str(n).encode())\n",
    "        del data['len']\n",
    "        \n",
    "\n",
    "        for i in tqdm.tqdm(data, total=len(data)):\n",
    "            value = data[i]\n",
    "            i = int(i)\n",
    "            for idx in range(len(self.camera_yaws)):\n",
    "               # put images\n",
    "                for cam, ext in [(\"wide\",\"jpg\"), (\"narr\", \"jpg\"), (\"wide_sem\",\"png\"), (\"narr_sem\", \"png\")]:\n",
    "                    self.total_image_size += self.read_and_put_image(txn, os.path.join(current_dir, \"rgbs\", f\"{cam}_{idx}_{i:05d}.{ext}\"))\n",
    "               # put labels\n",
    "                self.read_and_put_label(txn, i, current_dir)\n",
    "            txn.put(\n",
    "                f'loc_{i:05d}'.encode(),\n",
    "                np.ascontiguousarray(value['loc']).astype(np.float32)\n",
    "            )\n",
    "\n",
    "            txn.put(\n",
    "                f'rot_{i:05d}'.encode(),\n",
    "                np.ascontiguousarray(value['rot']).astype(np.float32)\n",
    "            )\n",
    "\n",
    "            txn.put(\n",
    "                f'spd_{i:05d}'.encode(),\n",
    "                np.ascontiguousarray(value['spd']).astype(np.float32)\n",
    "            )\n",
    "\n",
    "\n",
    "            txn.put(\n",
    "                f'cmd_{i:05d}'.encode(),\n",
    "                np.ascontiguousarray(value['cmd']).astype(np.float32)\n",
    "            )\n",
    "        \n",
    "    def dataset_to_lmdb(self):\n",
    "        isdir = os.path.isdir(self.data_dir)\n",
    "\n",
    "        for full_path in glob.glob(f'{self.data_dir}/**'):\n",
    "            if not os.path.isdir(full_path):\n",
    "                continue\n",
    "            txn = lmdb.open(full_path, subdir=isdir,\n",
    "                       map_size=1099511627776 * 2, readonly=False,\n",
    "                       meminit=False, map_async=True).begin(write=True)\n",
    "            with open(os.path.join(full_path, \"data.json\")) as file:\n",
    "                data = json.load(file)\n",
    "                self.put_data(txn, data, full_path)\n",
    "            txn.commit()\n",
    "        print(\"Images occupy: \", self.total_image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "177d48a9-e0a5-465e-80fb-19a892b25203",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 195/195 [00:00<00:00, 256.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images occupy:  22693898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_to_lmdb = DatasetToLMDB(\"dataset\", \"WorldOnRails/config.yaml\")\n",
    "dataset_to_lmdb.dataset_to_lmdb()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10b8a86-b498-422c-aacd-9f3e541ceee4",
   "metadata": {},
   "source": [
    "#### label image dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "855ca810-75c5-42f5-b32c-b6c14994774a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "bl_image_path = \"dataset/adyhsylssx/rgbs/lbl_03_00189.png\"\n",
    "image = np.asarray(Image.open(bl_image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "010f930d-9200-4666-a59f-2f8dbe4c8f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96, 96)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f611070-fc0d-4a56-a23d-760537a52de5",
   "metadata": {},
   "source": [
    "## Main dataset test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfa8ae69-83ca-4d49-a833-4053645c6bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MainDataset(Dataset):\n",
    "    def __init__(self, data_dir, config_path):\n",
    "            super().__init__()\n",
    "\n",
    "            with open(config_path, 'r') as f:\n",
    "                config = yaml.safe_load(f)\n",
    "\n",
    "            self.T = config['num_plan']\n",
    "            self.camera_yaws = config['camera_yaws']\n",
    "            self.wide_crop_top = config['wide_crop_top']\n",
    "            self.narr_crop_bottom = config['narr_crop_bottom']\n",
    "            self.seg_channels = config['seg_channels']\n",
    "\n",
    "            self.num_speeds = config['num_speeds']\n",
    "            self.num_steers = config['num_steers']\n",
    "            self.num_throts = config['num_throts']\n",
    "\n",
    "            # Ablation options\n",
    "            self.multi_cam = config['multi_cam']\n",
    "\n",
    "            self.num_frames = 0\n",
    "            self.txn_map = dict()\n",
    "            self.idx_map = dict()\n",
    "            self.yaw_map = dict()\n",
    "            self.file_map = dict()\n",
    "\n",
    "            # Load dataset\n",
    "            for full_path in glob.glob(f'{data_dir}/**'):\n",
    "                txn = lmdb.open(\n",
    "                    full_path,\n",
    "                    max_readers=1, readonly=True,\n",
    "                    lock=False, readahead=False, meminit=False).begin(write=False)\n",
    "\n",
    "                n = int(txn.get('len'.encode()))\n",
    "                if n < self.T+1:\n",
    "                    print (full_path, ' is too small. consider deleting it.')\n",
    "                    txn.__exit__()\n",
    "                else:\n",
    "                    offset = self.num_frames\n",
    "                    for i in range(n-self.T):\n",
    "                        self.num_frames += 1\n",
    "                        for j in range(len(self.camera_yaws)):\n",
    "                            self.txn_map[(offset+i)*len(self.camera_yaws)+j] = txn\n",
    "                            self.idx_map[(offset+i)*len(self.camera_yaws)+j] = i\n",
    "                            self.yaw_map[(offset+i)*len(self.camera_yaws)+j] = j\n",
    "                            self.file_map[(offset+i)*len(self.camera_yaws)+j] = full_path\n",
    "\n",
    "            print(f'{data_dir}: {self.num_frames} frames (x{len(self.camera_yaws)})')\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.multi_cam:\n",
    "            return self.num_frames*len(self.camera_yaws)\n",
    "        else:\n",
    "            return self.num_frames\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        if not self.multi_cam:\n",
    "            idx *= len(self.camera_yaws)\n",
    "\n",
    "        lmdb_txn = self.txn_map[idx]\n",
    "        index = self.idx_map[idx]\n",
    "        cam_index = self.yaw_map[idx]\n",
    "\n",
    "        locs = self.__class__.access('loc', lmdb_txn, index, self.T+1, dtype=np.float32)\n",
    "        rots = self.__class__.access('rot', lmdb_txn, index, self.T, dtype=np.float32)\n",
    "        spds = self.__class__.access('spd', lmdb_txn, index, self.T, dtype=np.float32).flatten()\n",
    "        \n",
    "        decode = lambda x : cv2.imdecode(x, -1)\n",
    "        lbls = np.stack([self.__class__.access(f'lbl_{d:02d}', lmdb_txn, index+1, self.T, dtype=np.uint8, preprocess=decode) for d in range(0,12)], axis=3)\n",
    "        wide_rgb = self.__class__.access('wide_{}'.format(cam_index),  lmdb_txn, index, 1, dtype=np.uint8, preprocess=decode).reshape(240, 480, 3)\n",
    "        wide_sem = self.__class__.access('wide_sem_{}'.format(cam_index),  lmdb_txn, index, 1, dtype=np.uint8, preprocess=decode).reshape(240,480, 3)\n",
    "        narr_rgb = self.__class__.access('narr_{}'.format(cam_index),  lmdb_txn, index, 1, dtype=np.uint8, preprocess=decode).reshape(240,384,3)\n",
    "        \n",
    "        cmd = self.__class__.access('cmd', lmdb_txn, index, 1, dtype=np.float32).flatten()\n",
    "\n",
    "        #wide_sem = filter_sem(wide_sem, self.seg_channels)\n",
    "\n",
    "        # Crop cameras\n",
    "        wide_rgb = wide_rgb[self.wide_crop_top:,:,::-1]\n",
    "        wide_sem = wide_sem[self.wide_crop_top:]\n",
    "        narr_rgb = narr_rgb[:-self.narr_crop_bottom,:,::-1]\n",
    "\n",
    "        return wide_rgb, wide_sem, narr_rgb, lbls, locs, rots, spds, int(cmd)\n",
    "    \n",
    "    @staticmethod\n",
    "    def access(tag, lmdb_txn, index, T, dtype=np.float32, preprocess = (lambda x : x)):\n",
    "        return np.stack([preprocess(np.frombuffer(lmdb_txn.get((f'{tag}_{t:05d}').encode()), dtype)) for t in range(index,index+T)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69771ed0-149c-4aca-a927-52d10414bc58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: 195 frames (x3)\n"
     ]
    }
   ],
   "source": [
    "dataset = MainDataset(\"dataset\", \"WorldOnRails/config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cac3673e-2296-4631-af99-03744380fc6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f1da026ac70>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAOTUlEQVR4nO3dfYxVhZnH8e+PuUxHBqkMq+N0XnZYwCIxURriKpJlI5J12Ub5wxhqRdyQ8E/X2pekld3EZk2Ma9LUkrhpMtFtWEOqXaqrMU0bl1oTiWFFMFsFUVaogKgYX0okBnGe/eMeNiPOyIX7ci48v08yYc459855OPCde+6ZOzOKCMzs7Dep7AHMrDUcu1kSjt0sCcduloRjN0vCsZslUVfskq6VtEvSbkl3NGooM2s8ne7X2SV1AK8CS4H9wPPANyJiR+PGM7NGqdRx38uB3RHxOoCkh4HrgQljl+RX8BQ6OzsZHh7m3HPPLXuUUh05coQ9e/bw8ccflz3KWSMiNN76emLvB/aNWd4P/OWJN5K0BlhTx37OSn19fYyMjLB48eKyRynVtm3bWLlyJTt2+ISw2eqJvSYRMQKMgB/ZzcpUzwW6A8DgmOWBYp2ZtaF6Yn8emCNppqROYAXwRGPGMrNGO+3T+Ig4JukfgN8CHcC/RcTLDZvMzBqqrufsEfFr4NcNmsXMmsivoDNLwrGbJeHYzZJw7GZJOHazJBy7WRKO3SwJx26WhGM3S8KxmyXh2M2ScOxmSTh2syQcu1kSjt0siab/DDr7rL6+PhYuXMjQ0BC9vb1lj2OJOPYWmzt3LnfffTf9/f2cc845ZY9jiTj2FqtUKnR3dzN16tSyRynVe++9x759+9ixYwdHjhwpe5wUHLuVYvPmzdx11128++67vPnmm2WPk4Jjt1J8+OGH7Nq1i8OHD5c9Shq+Gm+WhGM3S8KxmyXh2M2ScOxmSTh2syQcu1kSjt0sCcduloRjN0vCsZsl4dfGWxpdXV0sWbKEWbNmlT1K0zz88MMTbnPslsbUqVO59dZbue6668oepWmeffbZCbc5divFhRdeyOLFi/noo48+t23Pnj3s3bu3KfutVCp0dnY25WO3A0kTbnPsVoqFCxcyd+5cRkdHP7M+Ili3bh3r1q373Darj2O3UkyZMoUpU6Z8bn1EMDQ0xODgYMNj7+npSf2jwBy7tRVJLF++nEsvvZSIaOjH7uzsZO7cuQ39mGeSk8YuaRD4d6AXCGAkItZJ6gEeAYaBvcCNEfF+80a1LIaHhxkeHi57jLNOLV9nPwZ8PyLmAVcA35I0D7gD2BQRc4BNxbKZtamTxh4RByNiW/H+YWAn0A9cD6wvbrYeWN6kGc2sAU7pObukYWA+sAXojYiDxaa3qJ7mj3efNcCaOmY0swao+eWykqYCvwK+ExF/GrstqldSxr2aEhEjEbEgIhbUNamZ1aWm2CVNphr6hoh4tFj9tqS+Ynsf8E5zRjSzRjhp7Kq+JOdBYGdE/GTMpieAVcX7q4DHGz+emTVKLc/ZrwJWAn+Q9GKx7h+BfwF+KWk18EfgxqZMaGYNcdLYI+JZYKIX3C5p7Dhm1iz+fnazJBy7WRKO3SwJfyNMi8yePZtLLrmEyy67bNzv9jJrNsfeIkuXLuXOO++ku7ub7u7ussexhBx7i3R1dTFjxgwmT55c9iiWlJ+zmyXhR/Ym6+rqYvLkyXR1dZU9iiXn2Juoq6uLW265hUWLFnHxxRfT0dFR9kiWmGNvosmTJ7No0SJWrlxZ9ihmrY29t7eXm2++uZW7rMm2bdt45plnGvYDDnt6eli2bBmDg4PMmzevIR/TrF4tjb2/v5977rmnlbusyf3338/mzZs5evRoQz7eBRdcwG233cb8+fN96m5to6WxS2rLLz1NFKQk5syZw9DQ0Bf+8P0TDQ0N0dPT05Z/V8vLz9m/QKVS4aabbmL16tWndL/Ozk6mT5/epKnMTo9jB6ZNm8bQ0BDHjh37zPpKpcLg4CADAwMlTWbWOI4duOaaa5g1a9bnLtBNmjSJmTNnljSVWWM5dmBgYMCP3nbW88tlzZJw7GZJOHazJBy7WRKO3SwJx26WhGM3S8KxmyXh2M2ScOxmSTh2syQcu1kSjt0sCcduloRjN0vCsZsl4djNknDsZkk4drMkao5dUoek7ZKeLJZnStoiabekRyR1Nm9MM6vXqTyy3w7sHLN8L3BfRMwG3gdO7Yerm1lL1RS7pAHg74AHimUBVwMbi5usB5Y3YT4za5BaH9l/CvwAOP6D1WcAH0TE8d+qsB/oH++OktZI2ipp66FDh+qZ1czqcNLYJX0deCciXjidHUTESEQsiIgF559//ul8CDNrgFp+ScRVwHWSlgFdwDRgHXCepErx6D4AHGjemGZWr5M+skfE2ogYiIhhYAXwu4j4JvA0cENxs1XA402b0szqVs/X2X8IfE/SbqrP4R9szEhm1gyn9LveIuL3wO+L918HLm/8SGbWDH4FnVkSjt0sCcduloRjN0vCsZsl4djNknDsZkk4drMkHLtZEo7dLAnHbpaEYzdLwrGbJeHYzZJw7GZJOHazJBy7WRKO3SwJx26WhGM3S8KxmyXh2M2ScOxmSTh2syQcu1kSjt0sCcduloRjN0vilH6xo9nZ4vDhwxw+fJjR0dGyR2moo0ePTrjNsVs6EcFjjz3Ghg0biIiyx2movXv3TritpbFHBJ988kkrd9l2Jk2aREdHR9ljlC4i+PTTT0uJbXR0lFdffZWnnnrqrIv9i7Q09gMHDrB27dpW7rLtXHTRRaxYsYJp06aVPUqptm/fzsaNG7/wtLNZRkdHee6551KFDlQ/w7bqDYjsb0uXLo19+/ZFdg899FBMmzat9H+Ps/EtJujPV+OtNJHtkbVkjt0sCcdulkRNsUs6T9JGSa9I2inpSkk9kp6S9Frx5/RmD2tmp6/WR/Z1wG8iYi5wKbATuAPYFBFzgE3Fspm1qZPGLunLwF8BDwJExNGI+AC4Hlhf3Gw9sLw5I5pZI9TyyD4TOAT8XNJ2SQ9I6gZ6I+JgcZu3gN7x7ixpjaStkrY2ZmQzOx21xF4Bvgb8LCLmAx9xwil7VL+GMu7XUSJiJCIWRMSCeoc1s9NXS+z7gf0RsaVY3kg1/rcl9QEUf77TnBHNrBFOGntEvAXsk/TVYtUSYAfwBLCqWLcKeLwpE5pZQ9T62vjbgA2SOoHXgb+n+onil5JWA38EbmzOiGbWCDXFHhEvAuM9517S0GnMrGn8CjqzJBy7WRKO3SwJx26WhGM3S8KxmyXh2M2ScOxmSTh2syQcu1kSjt0sCcduloRjN0vCsZsl4djNknDsZkk4drMkHLtZEo7dLAnHbpaEYzdLwrGbJeHYzZJw7GZJOHazJBy7WRKO3SwJx26WhGM3S8KxmyXh2M2ScOxmSTh2syQcu1kSjt0sCcdulkRNsUv6rqSXJb0k6ReSuiTNlLRF0m5Jj0jqbPawZnb6Thq7pH7g28CCiLgE6ABWAPcC90XEbOB9YHUzBzWz+tR6Gl8BzpFUAaYAB4GrgY3F9vXA8oZPZ2YNc9LYI+IA8GPgDaqRfwi8AHwQEceKm+0H+ps1pJnVr5bT+OnA9cBM4CtAN3BtrTuQtEbSVklbT3tKM6tbpYbbXAPsiYhDAJIeBa4CzpNUKR7dB4AD4905IkaAkeK+0ZCpzeyU1fKc/Q3gCklTJAlYAuwAngZuKG6zCni8OSOaWSPU8px9C9ULcduAPxT3GQF+CHxP0m5gBvBgE+c0szrVchpPRPwI+NEJq18HLm/4RGbWFH4FnVkSjt0sCcduloRjN0vCsZsl4djNknDsZkk4drMkHLtZEo7dLAnHbpaEYzdLwrGbJeHYzZJw7GZJOHazJBy7WRKO3SwJx26WhGM3S8KxmyXh2M2ScOxmSTh2syQcu1kSjt0sCcduloRjN0vCsZsl4djNklBEtG5n0iHgI+Ddlu20Mf6MM29mODPn9sz1+fOIOH+8DS2NHUDS1ohY0NKd1ulMnBnOzLk9c/P4NN4sCcdulkQZsY+UsM96nYkzw5k5t2dukpY/Zzezcvg03iwJx26WRMtil3StpF2Sdku6o1X7PVWSBiU9LWmHpJcl3V6s75H0lKTXij+nlz3riSR1SNou6clieaakLcUxf0RSZ9kzjiXpPEkbJb0iaaekK8+Q4/zd4v/GS5J+Iamr3Y81tCh2SR3AvwJ/C8wDviFpXiv2fRqOAd+PiHnAFcC3ilnvADZFxBxgU7Hcbm4Hdo5Zvhe4LyJmA+8Dq0uZamLrgN9ExFzgUqqzt/VxltQPfBtYEBGXAB3ACtr/WENENP0NuBL47ZjltcDaVuy7AbM/DiwFdgF9xbo+YFfZs50w5wDVOK4GngRE9VVdlfH+Dcp+A74M7KG4SDxmfbsf535gH9ADVIpj/TftfKyPv7XqNP74ATpuf7GurUkaBuYDW4DeiDhYbHoL6C1rrgn8FPgBMFoszwA+iIhjxXK7HfOZwCHg58VTjwckddPmxzkiDgA/Bt4ADgIfAi/Q3sca8AW6CUmaCvwK+E5E/Gnstqh++m6br1lK+jrwTkS8UPYsp6ACfA34WUTMp/o9E585ZW+34wxQXEO4nuonq68A3cC1pQ5Vo1bFfgAYHLM8UKxrS5ImUw19Q0Q8Wqx+W1Jfsb0PeKes+cZxFXCdpL3Aw1RP5dcB50mqFLdpt2O+H9gfEVuK5Y1U42/n4wxwDbAnIg5FxCfAo1SPfzsfa6B1sT8PzCmuWHZSvaDxRIv2fUokCXgQ2BkRPxmz6QlgVfH+KqrP5dtCRKyNiIGIGKZ6bH8XEd8EngZuKG7WbjO/BeyT9NVi1RJgB218nAtvAFdImlL8Xzk+d9se6//Xwgsby4BXgf8F/qnsixVfMOciqqeO/wO8WLwto/oceBPwGvBfQE/Zs04w/18DTxbv/wXw38Bu4D+AL5U93wmzXgZsLY71fwLTz4TjDPwz8ArwEvAQ8KV2P9YR4ZfLmmXhC3RmSTh2syQcu1kSjt0sCcduloRjN0vCsZsl8X92gVTn3MPBLgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(dataset[0][3][0,:,:,0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f457f75d-3f5e-4552-9553-20aa8b0998a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 96, 96, 12)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][3][.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772a63ff-af4f-4c56-bf4f-4f097b3f63bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
